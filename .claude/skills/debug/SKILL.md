---
name: debug
description: Debug AOD Engine and LangGraph project issues. Use when things aren't working — empty responses, infinite loops, wrong routing, state corruption, tool failures, skills engine merge conflicts, or checkpointer problems. Covers graph execution, state management, tracing, and the skills engine.
---

# AOD Engine Debugging

This guide covers debugging LangGraph projects generated by AOD Engine, as well as the skills engine itself.

## Architecture Overview

```
AOD Engine (creator)                     Generated LangGraph Project (runtime)
─────────────────────────────────────────────────────────────────────────────
.claude/skills/                          src/
    apply.ts  ─── three-way merge ──>        graph.py         ← StateGraph
    state.ts  ─── tracks .aod/ ──────>       agents/          ← Agent nodes
    merge.ts                                 routers/         ← LLM/sticky routers
    structured.ts                            state.py         ← TypedDict state
.aod/                                        tools/           ← Tool definitions
    base/      ← pristine snapshots      .env
    state.yaml ← applied skills log      pyproject.toml
```

The AOD Engine builds the project topology. Once built, the runtime is a standard Python LangGraph process — no containers, no host-side orchestration.

---

## Part 1: LangGraph Graph Execution Issues

### 1.1 Empty or Silent Responses

The agent returns nothing, an empty string, or the graph ends without producing output.

**Diagnosis steps:**

```python
# Add tracing to your graph invocation
import langchain_core.callbacks
from langchain_core.tracers import ConsoleCallbackHandler

result = graph.invoke(
    {"messages": [HumanMessage(content="hello")]},
    config={"callbacks": [ConsoleCallbackHandler()]}
)
print("Final state:", result)
print("Messages:", result.get("messages", []))
```

**Common causes:**

1. **Conditional edge returns `None`:** The router function returns `None` instead of a valid node name.
   ```python
   # BAD — returns None implicitly when no branch matches
   def route(state):
       if state["intent"] == "search":
           return "search_agent"
       # Forgot the default case — returns None → graph silently ends

   # GOOD
   def route(state):
       if state["intent"] == "search":
           return "search_agent"
       return "fallback_agent"  # Always return a valid node or END
   ```

2. **Missing `END` import or wrong termination:**
   ```python
   from langgraph.graph import StateGraph, END

   # Ensure at least one path reaches END
   builder.add_edge("last_node", END)
   ```

3. **State field never populated:** A node reads from a field that was never set.
   ```python
   # Check your TypedDict for Optional fields with no default
   class AgentState(TypedDict):
       messages: Annotated[list, add_messages]
       result: str  # If no node writes this, downstream nodes get KeyError
   ```
   Fix: use `Optional[str]` with `None` as default, or ensure every path writes the field.

4. **LLM returned an empty content block:** Some models return tool_calls with empty content. Check:
   ```python
   for msg in result["messages"]:
       print(type(msg).__name__, repr(msg.content[:80] if msg.content else "<EMPTY>"))
   ```

---

### 1.2 Infinite Loops

The graph runs indefinitely, cycling between nodes without terminating.

**Diagnosis — add recursion limit and log each step:**

```python
from langgraph.errors import GraphRecursionError

try:
    result = graph.invoke(
        state,
        config={"recursion_limit": 10}  # Lower limit to fail fast
    )
except GraphRecursionError as e:
    print("Recursion limit hit:", e)
    # The error message shows the last active node
```

**Enable step-by-step tracing:**

```python
for step in graph.stream(state, config={"recursion_limit": 10}):
    node_name = list(step.keys())[0]
    print(f"Step: {node_name}")
    node_output = step[node_name]
    if "messages" in node_output:
        last_msg = node_output["messages"][-1]
        print(f"  Last message: {type(last_msg).__name__}: {repr(str(last_msg.content)[:100])}")
```

**Common causes:**

1. **Router always returns same node:** The routing condition never changes.
   ```python
   # BUG: intent is set once and never updated — router loops forever
   def route(state):
       return state["current_agent"]  # Never changes after first set

   # FIX: check for a termination condition first
   def route(state):
       if state.get("task_complete"):
           return END
       return state["current_agent"]
   ```

2. **ReAct agent never decides to stop:** The agent keeps calling tools without reaching a final answer.
   - Check that your system prompt instructs the agent to finalize.
   - Verify the `tools_condition` edge is wired: `builder.add_conditional_edges(agent_node, tools_condition)`.
   - Set `max_iterations` if using a prebuilt ReAct executor.

3. **Two nodes forwarding to each other:** A → B → A with no exit condition.
   ```python
   # Trace the edge map
   print(graph.get_graph().edges)
   ```

4. **Supervisor re-routes to an already-completed agent:** Add a visited set to state.
   ```python
   class SupervisorState(TypedDict):
       messages: Annotated[list, add_messages]
       visited: list[str]  # Track which agents have run

   def supervisor_route(state):
       for agent in available_agents:
           if agent not in state["visited"]:
               return agent
       return END
   ```

---

### 1.3 Wrong Routing Decisions

The LLM router sends messages to the wrong agent or `END` prematurely.

**Diagnosis — inspect router output:**

```python
# Temporarily make the router node print its decision
def router_node(state):
    decision = llm_router(state)
    print(f"[ROUTER] Input: {state['messages'][-1].content[:80]}")
    print(f"[ROUTER] Decision: {decision}")
    return decision
```

**Check the router prompt:**

```python
# Print the exact prompt the LLM sees
from langchain_core.messages import SystemMessage
messages = [SystemMessage(content=router_system_prompt)] + state["messages"]
for m in messages:
    print(f"[{type(m).__name__}] {m.content[:120]}")
```

**Common causes:**

1. **Agent names in prompt don't match node names:** The router LLM outputs `"search"` but the node is named `"search_agent"`.
   ```python
   # Enforce structured output with Literal type
   from typing import Literal
   from pydantic import BaseModel

   class RouterDecision(BaseModel):
       next: Literal["search_agent", "summarize_agent", "END"]

   router_llm = llm.with_structured_output(RouterDecision)
   ```

2. **Sticky router not resetting:** If using `sticky_router.py`, check the sticky field is cleared when the task changes.

3. **Intent classifier returning wrong label:** Test the classifier in isolation.
   ```python
   from src.hooks.intent_classifier import classify_intent
   result = classify_intent("what is the weather in Paris?")
   print(result)  # Should match a known intent
   ```

---

## Part 2: State Issues

### 2.1 Missing State Fields / KeyError

```
KeyError: 'result'
KeyError: 'intent'
```

**Diagnosis:**

```python
# Print full state at node entry
def my_node(state):
    print("State keys:", list(state.keys()))
    print("State:", state)
    ...
```

**Common causes:**

1. **TypedDict field not initialized:** LangGraph does not auto-initialize Optional fields.
   ```python
   # BAD — no default, KeyError if node never ran
   class State(TypedDict):
       messages: Annotated[list, add_messages]
       summary: str

   # GOOD — use Optional with default in the initial state dict
   class State(TypedDict):
       messages: Annotated[list, add_messages]
       summary: Optional[str]

   # And initialize explicitly:
   initial_state = {"messages": [], "summary": None}
   ```

2. **Subgraph state not merged back:** When using subgraphs, the parent state only sees keys that the subgraph explicitly returns.
   ```python
   # Ensure subgraph output keys match parent state keys
   def subgraph_entry(state: ParentState) -> SubgraphState:
       return {"messages": state["messages"]}

   def subgraph_exit(substate: SubgraphState) -> dict:
       return {"messages": substate["messages"], "result": substate["result"]}
   ```

3. **Parallel node writes conflicting values:** In a fan-out pattern, two nodes write the same key — the last one wins unless you use a reducer.
   ```python
   from operator import add
   from typing import Annotated

   class State(TypedDict):
       # Accumulates all results from parallel nodes instead of overwriting
       results: Annotated[list[str], add]
   ```

---

### 2.2 Duplicated Messages

The `messages` list contains the same message multiple times.

**Cause:** Using `add_messages` reducer (which appends) but also manually appending in node code.

```python
# BAD — double append
def my_node(state):
    new_msg = AIMessage(content="hello")
    state["messages"].append(new_msg)   # Manual append
    return {"messages": [new_msg]}       # add_messages appends again

# GOOD — only return the new message, let the reducer handle it
def my_node(state):
    new_msg = AIMessage(content="hello")
    return {"messages": [new_msg]}
```

**Check your reducer:**

```python
from langgraph.graph.message import add_messages
# add_messages deduplicates by message id — ensure each message has a unique id
from langchain_core.messages import AIMessage
import uuid
msg = AIMessage(content="hello", id=str(uuid.uuid4()))
```

---

### 2.3 State Not Persisted Between Invocations

Each call to `graph.invoke()` starts fresh — previous conversation is lost.

**Fix:** Add a checkpointer.

```python
from langgraph.checkpoint.memory import MemorySaver
# or for persistent storage:
from langgraph.checkpoint.sqlite import SqliteSaver

checkpointer = MemorySaver()
graph = builder.compile(checkpointer=checkpointer)

# Use a thread_id to identify the conversation
config = {"configurable": {"thread_id": "user-123"}}

# First call
graph.invoke({"messages": [HumanMessage("hello")]}, config=config)

# Second call — resumes from previous state
graph.invoke({"messages": [HumanMessage("what did I just say?")]}, config=config)
```

---

## Part 3: Tool Failures

### 3.1 Tool Not Being Called

The agent outputs text describing what it would do instead of calling the tool.

**Diagnosis:**

```python
# Check tools are bound to the LLM
print(agent_llm.kwargs.get("tools", []))  # For ChatOpenAI / ChatAnthropic
```

**Common causes:**

1. **Tool not bound:** `llm.bind_tools([tool1, tool2])` was not called, or a wrong list was passed.
2. **System prompt discourages tool use:** The system prompt says "answer directly" without mentioning tools.
3. **Tool schema invalid:** Pydantic validation error prevents the tool from being registered.
   ```python
   from langchain_core.tools import tool

   @tool
   def my_tool(query: str) -> str:
       """Search for information. Args: query: the search query."""
       return search(query)

   # Verify it's valid
   print(my_tool.name)
   print(my_tool.description)
   print(my_tool.args_schema.schema())
   ```

### 3.2 Tool Raises an Exception

```
ToolException: ...
ValueError: ...
```

**Strategy:** Wrap tool execution in try/except and return a structured error message so the agent can recover.

```python
@tool
def my_tool(query: str) -> str:
    """Search for information."""
    try:
        return search(query)
    except Exception as e:
        return f"Tool error: {type(e).__name__}: {e}. Try a different approach."
```

If using a prebuilt ReAct agent, set `handle_tool_errors=True`:

```python
from langgraph.prebuilt import create_react_agent

agent = create_react_agent(
    llm,
    tools,
    handle_tool_errors=True  # Catches ToolException and feeds error back to LLM
)
```

### 3.3 Tool Output Too Large

The LLM context window is exceeded because a tool returns a large document.

```python
@tool
def fetch_document(url: str) -> str:
    """Fetch a webpage."""
    content = requests.get(url).text
    # Truncate to avoid context overflow
    max_chars = 8000
    if len(content) > max_chars:
        content = content[:max_chars] + "\n[... truncated ...]"
    return content
```

---

## Part 4: Skills Engine Issues

### 4.1 Three-Way Merge Conflicts

When applying a skill fails with merge conflicts.

**Check state.yaml for applied skills:**

```bash
cat .aod/state.yaml
```

**Inspect the conflicted file:**

```bash
# The conflicted file will contain standard git conflict markers
grep -n "<<<<<<" src/graph.py
```

Resolve manually:

```
<<<<<<< current (your changes)
def my_custom_node(state):
    ...
=======
def my_custom_node(state):
    ... # skill's version
>>>>>>> skill
```

Edit the file to keep the correct version, removing all conflict markers. Then update the base snapshot:

```bash
npx tsx -e "
import { updateBase } from './skills-engine/apply.js';
updateBase('src/graph.py');
"
```

**Prevent future conflicts:** Keep customizations in separate files when possible. Add new nodes in their own module (e.g., `src/agents/my_custom_agent.py`) rather than modifying `src/graph.py` directly. Skills merge more cleanly when core files aren't heavily edited.

---

### 4.2 state.yaml Corruption or Inconsistency

The `.aod/state.yaml` file tracks which skills have been applied and what files they manage.

**Symptoms:**
- "skill already applied" when trying to re-apply
- Base snapshot out of sync with working tree
- Skill uninstall leaves orphaned files

**Inspect the state:**

```bash
cat .aod/state.yaml
```

Expected structure:

```yaml
version: "1"
applied_skills:
  - name: add-agent
    applied_at: "2024-01-15T10:23:00Z"
    files_added:
      - src/agents/search_agent.py
    files_modified:
      - src/graph.py
      - src/state.py
```

**If a skill entry is wrong, remove it carefully:**

```bash
# Back up first
cp .aod/state.yaml .aod/state.yaml.bak

# Edit with any text editor to remove the bad entry
# Then verify the base snapshots match
ls .aod/base/src/
```

**If base snapshots are out of sync with working tree**, rebuild them:

```bash
npx tsx -e "
import { rebuildBase } from './skills-engine/state.js';
rebuildBase();
"
```

---

### 4.3 Skill Apply Fails — Missing Dependencies

```
Error: Cannot find module './skills-engine/apply.js'
```

**Fix:** Build the skills engine first.

```bash
npm install
npm run build  # or: npx tsc
```

Then retry the skill application.

---

### 4.4 pyproject.toml / requirements.txt Merge Issues

The structured merge for Python dependencies failed or created duplicates.

**Inspect the file:**

```bash
cat pyproject.toml | grep -A20 "\[tool.poetry.dependencies\]"
# or
cat requirements.txt
```

**If duplicates exist**, deduplicate manually:

```bash
# For requirements.txt — sort and deduplicate
sort -u requirements.txt -o requirements.txt

# For pyproject.toml — edit manually and keep the higher version if duplicated
```

**Verify the environment:**

```bash
cd generated_project/
pip install -e .
python -c "import langgraph; print(langgraph.__version__)"
```

---

## Part 5: LangGraph-Specific Debugging

### 5.1 LangSmith Tracing

The most powerful debugging tool for LangGraph. Set up tracing to get full visibility.

```bash
# Add to .env in generated project
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__your_key_here
LANGCHAIN_PROJECT=my-project-debug
```

```python
# Or set in code before graph invocation
import os
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "ls__..."
os.environ["LANGCHAIN_PROJECT"] = "debug-session"
```

Once enabled, every `graph.invoke()` call produces a trace at https://smith.langchain.com showing:
- Each node execution with inputs and outputs
- LLM calls with full prompts and responses
- Tool calls and results
- Token usage and latency per step

---

### 5.2 Visualize the Graph Structure

Confirm the graph topology is what you expect before debugging logic.

```python
# Print ASCII graph
print(graph.get_graph().draw_ascii())

# Generate Mermaid diagram
print(graph.get_graph().draw_mermaid())

# Save as PNG (requires graphviz)
graph.get_graph().draw_png("graph.png")
```

Or use the `/visualize` skill:

```
/visualize
```

Compare the output against your intended topology. Look for:
- Missing edges (nodes that can never be reached)
- Missing paths to `END` (nodes that always loop)
- Unexpected conditional branches

---

### 5.3 Checkpointer Issues

**Symptom:** `graph.invoke()` raises `ValueError: thread_id required` or state is not persisted.

```python
# Always pass config with thread_id when using a checkpointer
config = {"configurable": {"thread_id": "conversation-1"}}
result = graph.invoke(state, config=config)
```

**Symptom:** State from a previous run bleeds into a new conversation.

```python
# Use a fresh thread_id for each new conversation
import uuid
config = {"configurable": {"thread_id": str(uuid.uuid4())}}
```

**Inspect checkpointer state:**

```python
# Get the full checkpoint for a thread
checkpoint = graph.get_state(config)
print("Values:", checkpoint.values)
print("Next nodes:", checkpoint.next)
print("Metadata:", checkpoint.metadata)
```

**Reset a thread:**

```python
# For MemorySaver — just use a new thread_id
# For SqliteSaver — delete from DB
import sqlite3
conn = sqlite3.connect("checkpoints.db")
conn.execute("DELETE FROM checkpoints WHERE thread_id = ?", ("conversation-1",))
conn.commit()
```

---

### 5.4 Async vs Sync Mismatch

LangGraph supports both sync and async. Mixing them causes errors.

```python
# If your graph uses async nodes, invoke with ainvoke
result = await graph.ainvoke(state, config=config)

# Sync nodes work with invoke
result = graph.invoke(state, config=config)

# Mixing — async node in sync graph invocation — raises:
# RuntimeError: This event loop is already running
# Fix: ensure all nodes are consistently async or sync
```

---

### 5.5 Subgraph Debugging

Subgraphs run as nested graphs. Their internal state is not visible in the parent trace by default.

```python
# Stream subgraph events with subgraphs=True
for chunk in graph.stream(state, config=config, subgraphs=True):
    print(chunk)
```

**Subgraph state type mismatch:**

```python
# Parent graph passes state to subgraph — keys must be compatible
# If subgraph expects a different TypedDict, add a transformation node

def prepare_for_subgraph(parent_state: ParentState) -> SubgraphState:
    return {
        "messages": parent_state["messages"],
        "context": parent_state.get("knowledge_base", {})
    }
```

---

## Part 6: Environment and Dependency Issues

### 6.1 Python Environment Problems

```bash
# Check Python version (LangGraph requires ≥ 3.11)
python --version

# Check LangGraph version
python -c "import langgraph; print(langgraph.__version__)"

# Check LangChain version
python -c "import langchain; print(langchain.__version__)"

# Reinstall dependencies cleanly
pip install -e ".[dev]"
# or with poetry:
poetry install
```

### 6.2 Missing API Keys

```python
# Check required env vars at startup
import os

required = ["ANTHROPIC_API_KEY"]  # or OPENAI_API_KEY, etc.
missing = [k for k in required if not os.environ.get(k)]
if missing:
    raise EnvironmentError(f"Missing required env vars: {missing}")
```

```bash
# Verify .env is loaded (if using python-dotenv)
python -c "
from dotenv import load_dotenv
load_dotenv()
import os
key = os.environ.get('ANTHROPIC_API_KEY', '')
print(f'API key: {len(key)} chars, starts with: {key[:10]}')
"
```

### 6.3 Import Errors After Skill Application

A skill added a new file but it has an import that doesn't exist yet.

```bash
# Test imports for all project modules
cd generated_project/
python -c "import src.graph"
python -c "from src.agents import search_agent"
```

Common fixes:
- Run `pip install -e .` to pick up new dependencies added by the skill
- Check if a library component was added to `src/` but its import path is wrong
- Ensure `__init__.py` exists in new package directories

---

## Part 7: Quick Diagnostic Checklist

Run through this checklist before deep-diving:

```bash
#!/bin/bash
echo "=== AOD Engine Project Diagnostics ==="

echo ""
echo "1. Python version (need 3.11+)?"
python --version

echo ""
echo "2. LangGraph installed?"
python -c "import langgraph; print('langgraph', langgraph.__version__)" 2>&1

echo ""
echo "3. .env file present with API key?"
[ -f .env ] && grep -q "API_KEY\|OAUTH_TOKEN" .env && echo "OK" || echo "MISSING or no key found"

echo ""
echo "4. AOD skills state initialized?"
[ -f .aod/state.yaml ] && echo "OK — $(grep 'name:' .aod/state.yaml | wc -l | tr -d ' ') skills applied" || echo "NOT INITIALIZED"

echo ""
echo "5. Base snapshots present?"
[ -d .aod/base ] && echo "OK — $(ls .aod/base/ | wc -l | tr -d ' ') dirs" || echo "MISSING"

echo ""
echo "6. Graph module importable?"
python -c "import src.graph; print('OK — graph compiled')" 2>&1

echo ""
echo "7. Conflict markers in source files?"
grep -rn "<<<<<<" src/ 2>/dev/null && echo "CONFLICT MARKERS FOUND — resolve before running" || echo "OK — no conflicts"

echo ""
echo "8. Skills engine built?"
[ -d skills-engine/dist ] && echo "OK" || echo "NOT BUILT — run: npm run build"
```

---

## Part 8: Common Error Messages Reference

| Error | Cause | Fix |
|-------|-------|-----|
| `GraphRecursionError` | Graph cycles without reaching END | Add exit condition or lower `recursion_limit` to diagnose |
| `KeyError: 'field_name'` | State field accessed before being set | Initialize all fields in the initial state dict |
| `ValueError: thread_id required` | Checkpointer used without config | Pass `config={"configurable": {"thread_id": "..."}}` |
| `InvalidUpdateError` | Node returned a key not in State TypedDict | Add the field to state or fix the return value |
| `ToolException` | Tool raised an error | Wrap tool in try/except or use `handle_tool_errors=True` |
| `RuntimeError: This event loop is already running` | Sync/async mismatch | Use `ainvoke` for async graphs |
| `TypeError: unhashable type: 'list'` | Reducer returning a list where a hashable was expected | Check your Annotated reducer types |
| `ModuleNotFoundError: No module named 'langgraph'` | Env not activated or pip install not run | Run `pip install -e .` in project dir |
| `merge conflict in src/graph.py` | Skills engine three-way merge found incompatible edits | Resolve conflict markers manually, update base snapshot |

---

## Part 9: Getting More Information

### Enable verbose LangChain logging

```python
import logging
logging.basicConfig(level=logging.DEBUG)
logging.getLogger("langchain").setLevel(logging.DEBUG)
logging.getLogger("langgraph").setLevel(logging.DEBUG)
```

### Inspect graph edges and nodes programmatically

```python
g = graph.get_graph()
print("Nodes:", list(g.nodes))
print("Edges:", [(e.source, e.target) for e in g.edges])
```

### Dump full state at any node

```python
def debug_node(state):
    import json
    print(json.dumps(
        {k: str(v)[:200] for k, v in state.items()},
        indent=2
    ))
    return {}  # Pass-through node — add it temporarily between any two nodes

builder.add_node("debug", debug_node)
builder.add_edge("node_before", "debug")
builder.add_edge("debug", "node_after")
```

### Check what skills-engine applied

```bash
# Full history of skill applications
cat .aod/state.yaml

# Files managed by the skills engine (base snapshots)
find .aod/base -type f | sort
```
